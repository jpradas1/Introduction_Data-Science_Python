{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec08dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673256d",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30fb17f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012308996455744264"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nhl_correlation():\n",
    "    # Let's bring in the Dataset to this exercise\n",
    "    nhl_df = pd.read_csv(\"Datasets/nhl.csv\")\n",
    "    cities = pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "    # Cleaning Wikipadia Data by using regex\n",
    "    for x in ['NFL', 'MLB', 'NBA', 'NHL']:\n",
    "        # There's team names that have character whithin of []\n",
    "        # Also, we replace void values with NaN values and in the team column we see there are multiple teams in one rows, \n",
    "        # so lets collapse them into a single string\n",
    "        cities[x] = cities[x].replace('\\[.*\\]', '', regex=True).replace('', np.nan).replace('[\\—*]', np.nan, regex=True)\n",
    "\n",
    "    # Let's change the name of the column 'Population (2016 est.)[8]' by 'Population', for convenience\n",
    "    cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population', 'NHL': 'team'})\n",
    "    # and we goint to use only the columns relation to the Big 4 Sports, population and its Metropolitan area\n",
    "    # let's drop NaN values as well\n",
    "    cities = cities[['Metropolitan area', 'Population', 'team']].dropna()\n",
    "    # In the team column we see there are multiple teams in one rows, so lets collapse them into a single array\n",
    "    cities['team'].iloc[0] = 'RangersIslandersDevils'\n",
    "    cities['team'].iloc[1] = 'KingsDucks'\n",
    "    cities['team'] = cities['team'].str.split(' ').str[-1].astype(str) # let's take into account just the last word of the each team\n",
    "\n",
    "    # Cleaning NHL Data\n",
    "    nhl_df['team'] = nhl_df['team'].replace('[\\*]', '', regex=True) # take away useless characters\n",
    "    nhl_df = nhl_df[nhl_df['year']==2018] # we're interested on data of 2018\n",
    "    nhl_df = nhl_df[['team', 'W', 'L', 'year']].drop([0, 9, 18, 26]) # only these columns are essential\n",
    "    # now we compute the win/loss ratio\n",
    "    nhl_df['win/loss'] = nhl_df['W'].astype(float)/(nhl_df['W'].astype(float) + nhl_df['L'].astype(float))\n",
    "    nhl_df['team'] = nhl_df['team'].str.split(' ').str[-1].astype(str) \n",
    "    nhl_df = nhl_df.set_index('team')\n",
    "\n",
    "    # now let's take the average on the team which belong of the seam metropolitan area\n",
    "        # new york --> 'Rangers', 'Islanders', 'Devils'\n",
    "        # los angeles --> 'Kings', 'Ducks'\n",
    "    W = int(nhl_df[nhl_df.index == 'Rangers'].values[0][0]) + int(nhl_df[nhl_df.index == 'Islanders'].values[0][0]) \\\n",
    "        + int(nhl_df[nhl_df.index == 'Devils'].values[0][0])\n",
    "    L = int(nhl_df[nhl_df.index == 'Rangers'].values[0][1]) + int(nhl_df[nhl_df.index == 'Islanders'].values[0][1]) \\\n",
    "        + int(nhl_df[nhl_df.index == 'Devils'].values[0][1])\n",
    "    mean = (nhl_df[nhl_df.index == 'Rangers'].values[0][-1] + nhl_df[nhl_df.index == 'Islanders'].values[0][-1] \\\n",
    "            + nhl_df[nhl_df.index == 'Devils'].values[0][-1])/3\n",
    "    new_york = {'team': 'RangersIslandersDevils',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(nhl_df[nhl_df.index == 'Kings'].values[0][0]) + int(nhl_df[nhl_df.index == 'Ducks'].values[0][0])\n",
    "    L = int(nhl_df[nhl_df.index == 'Kings'].values[0][1]) + int(nhl_df[nhl_df.index == 'Ducks'].values[0][1])\n",
    "    mean = (nhl_df[nhl_df.index == 'Kings'].values[0][-1] + nhl_df[nhl_df.index == 'Ducks'].values[0][-1])/2\n",
    "    los_angeles = {'team': 'KingsDucks',\n",
    "                   'W': W, 'L': L, 'year': 2018, \n",
    "                   'win/loss': W/(W+L)}\n",
    "    # let's drop these columns\n",
    "    nhl_df = nhl_df.reset_index()\n",
    "    nhl_df = nhl_df.drop([12,14,15,24,26])\n",
    "    # and let's add the rows related to new york and los angeles\n",
    "    nhl_df = nhl_df.append([new_york, los_angeles], ignore_index=True)\n",
    "\n",
    "    # finally, let's merge both nhl_df and cities data\n",
    "    merge = pd.merge(nhl_df, cities, how='outer', on='team')\n",
    "    merge['Population'] = merge['Population'].astype(float)\n",
    "    merge = merge.groupby('Metropolitan area').agg({'Population': np.mean, 'win/loss': np.mean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['win/loss'] # pass in win/loss ratio from nhl_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    return corr\n",
    "nhl_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0bdb7",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02194b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17657160252844614"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nba_correlation():\n",
    "    # Let's bring in the Dataset to this exercise\n",
    "    nba_df = pd.read_csv(\"Datasets/nba.csv\")\n",
    "    cities = pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "    # Cleaning Wikipadia Data by using regex\n",
    "    for x in ['NFL', 'MLB', 'NBA', 'NHL']:\n",
    "        # There's team names that have character whithin of []\n",
    "        # Also, we replace void values with NaN values and in the team column we see there are multiple teams in one rows, \n",
    "        # so lets collapse them into a single string\n",
    "        cities[x] = cities[x].replace('\\[.*\\]', '', regex=True).replace('', np.nan).replace('[\\—*]', np.nan, regex=True)\n",
    "\n",
    "    # Let's change the name of the column 'Population (2016 est.)[8]' by 'Population', for convenience\n",
    "    cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population', 'NBA': 'team'})\n",
    "    # and we goint to use only the columns relation to the Big 4 Sports, population and its Metropolitan area\n",
    "    # let's drop NaN values as well\n",
    "    cities = cities[['Metropolitan area', 'Population', 'team']].dropna()\n",
    "    # In the team column we see there are multiple teams in one rows, so lets collapse them into a single array\n",
    "    cities['team'].iloc[0] = 'KnicksNets'\n",
    "    cities['team'].iloc[1] = 'LakersClippers'\n",
    "    cities['team'] = cities['team'].str.split(' ').str[-1].astype(str) # let's take into account just the last word of the each team\n",
    "\n",
    "    # Cleaning NBA Data\n",
    "    nba_df['team'] = nba_df['team'].replace(['[\\*]','\\(.*\\)','\\s*$'], '', regex=True) # take away useless characters\n",
    "    nba_df = nba_df[nba_df['year']==2018] # we're interested on data of 2018\n",
    "    nba_df = nba_df[['team', 'W', 'L', 'year']] # only these columns are essential\n",
    "    # now we compute the win/loss ratio\n",
    "    nba_df['win/loss'] = nba_df['W'].astype(float)/(nba_df['W'].astype(float) + nba_df['L'].astype(float))\n",
    "    nba_df['team'] = nba_df['team'].str.split(' ').str[-1].astype(str) \n",
    "    nba_df = nba_df.set_index('team')\n",
    "\n",
    "    # now let's take the average on the team which belong of the seam metropolitan area\n",
    "            # new york --> 'Knicks', 'Nets'\n",
    "            # los angeles --> 'Lakers', 'Clippers'\n",
    "    W = int(nba_df[nba_df.index == 'Knicks'].values[0][0]) + int(nba_df[nba_df.index == 'Nets'].values[0][0])\n",
    "    L = int(nba_df[nba_df.index == 'Knicks'].values[0][1]) + int(nba_df[nba_df.index == 'Nets'].values[0][1])\n",
    "    mean = (nba_df[nba_df.index == 'Knicks'].values[0][-1] + nba_df[nba_df.index == 'Nets'].values[0][-1])/2\n",
    "    new_york = {'team': 'KnicksNets',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(nba_df[nba_df.index == 'Lakers'].values[0][0]) + int(nba_df[nba_df.index == 'Clippers'].values[0][0])\n",
    "    L = int(nba_df[nba_df.index == 'Lakers'].values[0][1]) + int(nba_df[nba_df.index == 'Clippers'].values[0][1])\n",
    "    mean = (nba_df[nba_df.index == 'Lakers'].values[0][-1] + nba_df[nba_df.index == 'Clippers'].values[0][-1])/2\n",
    "    los_angeles = {'team': 'LakersClippers',\n",
    "                   'W': W, 'L': L, 'year': 2018, \n",
    "                   'win/loss': W/(W+L)}\n",
    "    # let's drop these columns\n",
    "    nba_df = nba_df.reset_index()\n",
    "    nba_df = nba_df.drop([10,11,25,24])\n",
    "    # and let's add the rows related to new york and los angeles\n",
    "    nba_df = nba_df.append([new_york, los_angeles], ignore_index=True)\n",
    "\n",
    "    # finally, let's merge both nba_df and cities data\n",
    "    merge = pd.merge(nba_df, cities, how='outer', on='team')\n",
    "    merge['Population'] = merge['Population'].astype(float)\n",
    "    merge = merge.groupby('Metropolitan area').agg({'Population': np.mean, 'win/loss': np.mean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['win/loss'] # pass in win/loss ratio from nhl_df in the same order as cities[\"Metropolitan a\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    return corr\n",
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49638ef1",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb64cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1505230448710485"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mlb_correlation():    \n",
    "    # Let's bring in the Dataset to this exercise\n",
    "    mlb_df = pd.read_csv(\"Datasets/mlb.csv\")\n",
    "    cities = pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "    # Cleaning Wikipadia Data by using regex\n",
    "    for x in ['NFL', 'MLB', 'NBA', 'NHL']:\n",
    "        # There's team names that have character whithin of []\n",
    "        # Also, we replace void values with NaN values and in the team column we see there are multiple teams in one rows, \n",
    "        # so lets collapse them into a single string\n",
    "        cities[x] = cities[x].replace('\\[.*\\]', '', regex=True).replace('', np.nan).replace('[\\—*]', np.nan, regex=True)\n",
    "\n",
    "    # Let's change the name of the column 'Population (2016 est.)[8]' by 'Population', for convenience\n",
    "    cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population', 'MLB': 'team'})\n",
    "    # and we goint to use only the columns relation to the Big 4 Sports, population and its Metropolitan area\n",
    "    # let's drop NaN values as well\n",
    "    cities = cities[['Metropolitan area', 'Population', 'team']].dropna()\n",
    "    # In the team column we see there are multiple teams in one rows, so lets collapse them into a single array\n",
    "    cities['team'].iloc[0] = 'YankeesMets'\n",
    "    cities['team'].iloc[1] = 'DodgersAngels'\n",
    "    cities['team'].iloc[2] = 'GiantsAthletics'\n",
    "    cities['team'].iloc[3] = 'CubsWhiteSox'\n",
    "    cities['team'] = cities['team'].str.split(' ').str[-1].astype(str) # let's take into account just the last word of the each team\n",
    "\n",
    "    # Cleaning NBA Data\n",
    "    mlb_df['team'] = mlb_df['team'].replace(['[\\*]','\\(.*\\)','\\s*$'], '', regex=True) # take away useless characters\n",
    "    mlb_df = mlb_df[mlb_df['year']==2018] # we're interested on data of 2018\n",
    "    mlb_df = mlb_df[['team', 'W', 'L', 'year']] # only these columns are essential\n",
    "    mlb_df['team'].values[8] = 'WhiteSox'\n",
    "    # # now we compute the win/loss ratio\n",
    "    mlb_df['win/loss'] = mlb_df['W'].astype(float)/(mlb_df['W'].astype(float) + mlb_df['L'].astype(float))\n",
    "    mlb_df['team'] = mlb_df['team'].str.split(' ').str[-1].astype(str) \n",
    "    mlb_df = mlb_df.set_index('team')\n",
    "\n",
    "    # now let's take the average on the team which belong of the seam metropolitan area\n",
    "            # new york --> 'Yankees', 'Mets'\n",
    "            # los angeles --> 'Dodgers', 'Angels'\n",
    "            # san francisco --> 'Giants', 'Athletics'\n",
    "            # chicago --> 'Cubs' 'WhiteSox'\n",
    "    W = int(mlb_df[mlb_df.index == 'Yankees'].values[0][0]) + int(mlb_df[mlb_df.index == 'Mets'].values[0][0])\n",
    "    L = int(mlb_df[mlb_df.index == 'Yankees'].values[0][1]) + int(mlb_df[mlb_df.index == 'Mets'].values[0][1])\n",
    "    mean = (mlb_df[mlb_df.index == 'Yankees'].values[0][-1] + mlb_df[mlb_df.index == 'Mets'].values[0][-1])/2\n",
    "    new_york = {'team': 'YankeesMets',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(mlb_df[mlb_df.index == 'Dodgers'].values[0][0]) + int(mlb_df[mlb_df.index == 'Angels'].values[0][0])\n",
    "    L = int(mlb_df[mlb_df.index == 'Dodgers'].values[0][1]) + int(mlb_df[mlb_df.index == 'Angels'].values[0][1])\n",
    "    mean = (mlb_df[mlb_df.index == 'Dodgers'].values[0][-1] + mlb_df[mlb_df.index == 'Angels'].values[0][-1])/2\n",
    "    los_angeles = {'team': 'DodgersAngels',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(mlb_df[mlb_df.index == 'Giants'].values[0][0]) + int(mlb_df[mlb_df.index == 'Athletics'].values[0][0])\n",
    "    L = int(mlb_df[mlb_df.index == 'Giants'].values[0][1]) + int(mlb_df[mlb_df.index == 'Athletics'].values[0][1])\n",
    "    mean = (mlb_df[mlb_df.index == 'Giants'].values[0][-1] + mlb_df[mlb_df.index == 'Athletics'].values[0][-1])/2\n",
    "    san_francisco = {'team': 'GiantsAthletics',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(mlb_df[mlb_df.index == 'Cubs'].values[0][0]) + int(mlb_df[mlb_df.index == 'WhiteSox'].values[0][0])\n",
    "    L = int(mlb_df[mlb_df.index == 'Cubs'].values[0][1]) + int(mlb_df[mlb_df.index == 'WhiteSox'].values[0][1])\n",
    "    mean = (mlb_df[mlb_df.index == 'Cubs'].values[0][-1] + mlb_df[mlb_df.index == 'WhiteSox'].values[0][-1])/2\n",
    "    chicago = {'team': 'CubsWhiteSox',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    # let's drop these columns\n",
    "    mlb_df = mlb_df.reset_index()\n",
    "    mlb_df = mlb_df.drop([1,8,11,13,18,21,25,28])\n",
    "    # and let's add the rows related to new york, los angeles, san_francisco and chicago\n",
    "    mlb_df = mlb_df.append([new_york, los_angeles, san_francisco, chicago], ignore_index=True)\n",
    "\n",
    "    # finally, let's merge both mlb_df and cities data\n",
    "    merge = pd.merge(mlb_df, cities, how='outer', on='team')\n",
    "    merge['Population'] = merge['Population'].astype(float)\n",
    "    merge = merge.groupby('Metropolitan area').agg({'Population': np.mean, 'win/loss': np.mean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['win/loss'] # pass in win/loss ratio from mlb_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    return corr\n",
    "mlb_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998daa75",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec61634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004922112149349409"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nfl_correlation():    \n",
    "    # Let's bring in the Dataset to this exercise\n",
    "    nfl_df = pd.read_csv(\"Datasets/nfl.csv\")\n",
    "    cities = pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "    # Cleaning Wikipadia Data by using regex\n",
    "    for x in ['NFL', 'MLB', 'NBA', 'NHL']:\n",
    "        # There's team names that have character whithin of []\n",
    "        # Also, we replace void values with NaN values and in the team column we see there are multiple teams in one rows, \n",
    "        # so lets collapse them into a single string\n",
    "        cities[x] = cities[x].replace('\\[.*\\]', '', regex=True).replace('', np.nan).replace('[\\—*]', np.nan, regex=True)\n",
    "\n",
    "    # Let's change the name of the column 'Population (2016 est.)[8]' by 'Population', for convenience\n",
    "    cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population', 'NFL': 'team'})\n",
    "    # and we goint to use only the columns relation to the Big 4 Sports, population and its Metropolitan area\n",
    "    # let's drop NaN values as well\n",
    "    cities = cities[['Metropolitan area', 'Population', 'team']].dropna()\n",
    "    # In the team column we see there are multiple teams in one rows, so lets collapse them into a single array\n",
    "    cities['team'].iloc[0] = 'GiantsJets'\n",
    "    cities['team'].iloc[1] = 'RamsChargers'\n",
    "    cities['team'].iloc[2] = '49ersRaiders'\n",
    "    cities['team'] = cities['team'].str.split(' ').str[-1].astype(str) # let's take into account just the last word of the each team\n",
    "    cities\n",
    "\n",
    "    # Cleaning NFL Data\n",
    "    nfl_df['team'] = nfl_df['team'].replace(['[\\*]','\\(.*\\)','\\s*$','[\\+]'], '', regex=True) # take away useless characters\n",
    "    nfl_df = nfl_df[nfl_df['year']==2018] # we're interested on data of 2018\n",
    "    nfl_df = nfl_df[['team', 'W', 'L', 'year']].drop([0,5,10,15,20,25,30,35]) # only these columns are essential\n",
    "    # now we compute the win/loss ratio\n",
    "    nfl_df['win/loss'] = nfl_df['W'].astype(float)/(nfl_df['W'].astype(float) + nfl_df['L'].astype(float))\n",
    "    nfl_df['team'] = nfl_df['team'].str.split(' ').str[-1].astype(str) \n",
    "    nfl_df = nfl_df.set_index('team')\n",
    "\n",
    "    # now let's take the average on the team which belong of the seam metropolitan area\n",
    "            # new york --> 'Giants', 'Jets'\n",
    "            # los angeles --> 'Rams', 'Chargers'\n",
    "            # san francisco --> '49ers', 'Raiders'\n",
    "    W = int(nfl_df[nfl_df.index == 'Giants'].values[0][0]) + int(nfl_df[nfl_df.index == 'Jets'].values[0][0])\n",
    "    L = int(nfl_df[nfl_df.index == 'Giants'].values[0][1]) + int(nfl_df[nfl_df.index == 'Jets'].values[0][1])\n",
    "    mean = (nfl_df[nfl_df.index == 'Giants'].values[0][-1] + nfl_df[nfl_df.index == 'Jets'].values[0][-1])/2\n",
    "    new_york = {'team': 'GiantsJets',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(nfl_df[nfl_df.index == 'Rams'].values[0][0]) + int(nfl_df[nfl_df.index == 'Chargers'].values[0][0])\n",
    "    L = int(nfl_df[nfl_df.index == 'Rams'].values[0][1]) + int(nfl_df[nfl_df.index == 'Chargers'].values[0][1])\n",
    "    mean = (nfl_df[nfl_df.index == 'Rams'].values[0][-1] + nfl_df[nfl_df.index == 'Chargers'].values[0][-1])/2\n",
    "    los_angeles = {'team': 'RamsChargers',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    W = int(nfl_df[nfl_df.index == '49ers'].values[0][0]) + int(nfl_df[nfl_df.index == 'Raiders'].values[0][0])\n",
    "    L = int(nfl_df[nfl_df.index == '49ers'].values[0][1]) + int(nfl_df[nfl_df.index == 'Raiders'].values[0][1])\n",
    "    mean = (nfl_df[nfl_df.index == '49ers'].values[0][-1] + nfl_df[nfl_df.index == 'Raiders'].values[0][-1])/2\n",
    "    san_francisco = {'team': '49ersRaiders',\n",
    "                'W': W, 'L': L, 'year': 2018, \n",
    "                'win/loss': W/(W+L)}\n",
    "    # let's drop these columns\n",
    "    nfl_df = nfl_df.reset_index()\n",
    "    nfl_df = nfl_df.drop([3,19,15,13,28,30])\n",
    "    # and let's add the rows related to new york, los angeles and san francisco \n",
    "    nfl_df = nfl_df.append([new_york, los_angeles, san_francisco], ignore_index=True)\n",
    "\n",
    "    # finally, let's merge both mlb_df and cities data\n",
    "    merge = pd.merge(nfl_df, cities, how='outer', on='team')\n",
    "    merge['Population'] = merge['Population'].astype(float)\n",
    "    merge = merge.groupby('Metropolitan area').agg({'Population': np.mean, 'win/loss': np.mean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['win/loss'] # pass in win/loss ratio from nfl_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q4: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
    "\n",
    "    corr, pval = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    return corr\n",
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864cf357",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab191a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
